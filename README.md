---

# RAG-PDF-CHATBOT

## üìå Overview  
The **RAG-PDF-CHATBOT** enables users to upload PDF documents and ask questions, receiving intelligent responses based on the document content. It utilizes **Retrieval-Augmented Generation (RAG)** with **LLMs, embeddings, and a vector database** for efficient document-based querying.

### üîπ Key Technologies:
- **LLM & Embeddings**: OpenAI APIs (GPT-4 & `text-embedding-ada-002`)
- **Vector Storage**: Pinecone
- **Backend**: FastAPI (Python)
- **Frontend**: React
- **PDF Processing**: PyPDF2 (No OCR support)

---

## üèóÔ∏è System Architecture

### **High-Level Architecture Flow**

1. **User Interaction**

   - Users upload PDFs and submit queries via the **React frontend**.
   - The system processes queries using OpenAI's **LLM and stored vector embeddings**.

2. **Backend (FastAPI)**

   - Manages API endpoints for PDF upload, query retrieval, and LLM interaction.
   - Routes requests to different services (**document processing, vector storage, and query handling**).

3. **PDF Processing Module**

   - Extracts text from PDFs using **PyPDF2**.
   - Chunks text into **meaningful sections** for efficient retrieval.
   - Cleans and preprocesses extracted text.

4. **Embedding Model (OpenAI)**

   - Converts text chunks into vector embeddings using `text-embedding-ada-002`.
   - Stores embeddings in **Pinecone** for quick retrieval.

5. **Vector Database (Pinecone)**

   - Stores document chunks and corresponding **vector embeddings**.
   - Enables **fast similarity search** for retrieving relevant text sections.

6. **Retrieval & Context Builder**

   - Converts user queries into **vector embeddings**.
   - Searches Pinecone for **relevant document chunks**.
   - Constructs context from retrieved text for **LLM response generation**.

7. **LLM**

   - Processes user queries along with the **retrieved document context**.
   - Generates a well-structured response based on the available context.

8. **Response to User**
   - The chatbot sends the **final response** back to the frontend.
   - The response is displayed in the chat interface.

---

## üîÑ Data Flow Process

1Ô∏è‚É£ **User Uploads a PDF** ‚Üí The file is sent to the backend for processing.  
2Ô∏è‚É£ **Text Extraction & Chunking** ‚Üí Extracted text is cleaned and divided into smaller **chunks**.  
3Ô∏è‚É£ **Embedding Generation** ‚Üí Each chunk is converted into a **vector embedding** using OpenAI.  
4Ô∏è‚É£ **Storing in Pinecone** ‚Üí Vector embeddings are stored for **future retrieval**.  
5Ô∏è‚É£ **User Submits Query** ‚Üí The system retrieves **relevant document chunks** from Pinecone.  
6Ô∏è‚É£ **Context Building** ‚Üí The best-matching chunks are formatted as input to GPT-4.  
7Ô∏è‚É£ **Response Generation** ‚Üí GPT generates an answer based on the **retrieved context**.  
8Ô∏è‚É£ **Response Display** ‚Üí The response is sent back to the frontend and shown to the user.

---

## üõ†Ô∏è Evaluation of Responses

After querying the **RAG-PDF-API**, response evaluation is crucial. **LlamaIndex** provides several evaluation methods to ensure response quality.

### **Relevance Evaluation (No Ground Truth Needed)**

- Use **LlamaIndex's `RelevancyEvaluator`** to assess whether the generated responses are **relevant** based on the retrieved document context.
- No labeled datasets are required for this type of evaluation.

### üîó **Useful Links**

- [LlamaIndex Relevance Evaluation Guide](https://docs.llamaindex.ai/en/module_guides/evaluating/usage_pattern.html)
- [LlamaIndex Relevancy Evaluator](https://docs.llamaindex.ai/en/stable/examples/evaluation/relevancy_eval.html)
- [Evaluating Search with Human Judgment](https://dtunkelang.medium.com/evaluating-search-using-human-judgement-fbb2eeba37d9)

---

## üöÄ Getting Started

### **1Ô∏è‚É£ Clone the Repository**

```sh
git clone https://github.com/your-repo/rag-pdf-bot.git
cd rag-pdf-bot
cd ragbot-api
```

### **2Ô∏è‚É£ Install Dependencies**

```sh
pip install -r requirements.txt
```

### **3Ô∏è‚É£ Run the Backend**

```sh
uvicorn main:app --reload
```

### **4Ô∏è‚É£ Start the Frontend**

```sh
cd ../
cd ragbot-ui
npm install
npm start
```

---

## üéØ Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

---

## üìú License

MIT License. See `LICENSE` for details.
